{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with large datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and process static data\n",
    "This Section of the notebook \n",
    "1. downloads static data sources, \n",
    "2. loads them into memory, \n",
    "3. cleans that data then saves a cleaned data product, which may be used lateron for some analysis.\n",
    "\n",
    "### Download files from on-line host.\n",
    "Including this step in the pipeline ensures that the data processing steps are reproducible. This will save the severe headache that comes from trying to share particular cleaned data products.\n",
    "\n",
    "The script below will:\n",
    "\n",
    "1. Check if the data directory exists and clear it if it does.\n",
    "2. Create a new data directory.\n",
    "3. Download a list of specified data files from an online source into the directory.\n",
    "\n",
    "This approach ensures that everyone working on this project has access to the same data in its original form, facilitating consistent results across different environments.\n",
    "\n",
    "We will use Python for all operations, including file handling and downloading data, for simplicity and efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-06-12 03:00:12--  https://gdex.ucar.edu/dataset/camels/file/camels_clim.txt\n",
      "Resolving gdex.ucar.edu (gdex.ucar.edu)... 128.117.181.6\n",
      "Connecting to gdex.ucar.edu (gdex.ucar.edu)|128.117.181.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 \n",
      "Length: 100673 (98K) [text/plain]\n",
      "Saving to: ‘../data/camels/camels_clim.txt’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 50% 3.68M 0s\n",
      "    50K .......... .......... .......... .......... ........  100% 3.53M=0.03s\n",
      "\n",
      "2024-06-12 03:00:13 (3.60 MB/s) - ‘../data/camels/camels_clim.txt’ saved [100673/100673]\n",
      "\n",
      "--2024-06-12 03:00:13--  https://gdex.ucar.edu/dataset/camels/file/camels_geol.txt\n",
      "Resolving gdex.ucar.edu (gdex.ucar.edu)... 128.117.181.6\n",
      "Connecting to gdex.ucar.edu (gdex.ucar.edu)|128.117.181.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 \n",
      "Length: 71583 (70K) [text/plain]\n",
      "Saving to: ‘../data/camels/camels_geol.txt’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 71% 3.68M 0s\n",
      "    50K .......... .........                                  100% 1.50M=0.03s\n",
      "\n",
      "2024-06-12 03:00:13 (2.60 MB/s) - ‘../data/camels/camels_geol.txt’ saved [71583/71583]\n",
      "\n",
      "--2024-06-12 03:00:13--  https://gdex.ucar.edu/dataset/camels/file/camels_hydro.txt\n",
      "Resolving gdex.ucar.edu (gdex.ucar.edu)... 128.117.181.6\n",
      "Connecting to gdex.ucar.edu (gdex.ucar.edu)|128.117.181.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 \n",
      "Length: 122799 (120K) [text/plain]\n",
      "Saving to: ‘../data/camels/camels_hydro.txt’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 41% 3.78M 0s\n",
      "    50K .......... .......... .......... .......... .......... 83% 1.89M 0s\n",
      "   100K .......... .........                                  100% 70.0M=0.04s\n",
      "\n",
      "2024-06-12 03:00:13 (3.00 MB/s) - ‘../data/camels/camels_hydro.txt’ saved [122799/122799]\n",
      "\n",
      "--2024-06-12 03:00:13--  https://gdex.ucar.edu/dataset/camels/file/camels_name.txt\n",
      "Resolving gdex.ucar.edu (gdex.ucar.edu)... 128.117.181.6\n",
      "Connecting to gdex.ucar.edu (gdex.ucar.edu)|128.117.181.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 \n",
      "Length: 30417 (30K) [text/plain]\n",
      "Saving to: ‘../data/camels/camels_name.txt’\n",
      "\n",
      "     0K .......... .......... .........                       100%  262M=0s\n",
      "\n",
      "2024-06-12 03:00:14 (262 MB/s) - ‘../data/camels/camels_name.txt’ saved [30417/30417]\n",
      "\n",
      "--2024-06-12 03:00:14--  https://gdex.ucar.edu/dataset/camels/file/camels_soil.txt\n",
      "Resolving gdex.ucar.edu (gdex.ucar.edu)... 128.117.181.6\n",
      "Connecting to gdex.ucar.edu (gdex.ucar.edu)|128.117.181.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 \n",
      "Length: 109125 (107K) [text/plain]\n",
      "Saving to: ‘../data/camels/camels_soil.txt’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 46% 3.70M 0s\n",
      "    50K .......... .......... .......... .......... .......... 93% 1.85M 0s\n",
      "   100K ......                                                100% 72.2M=0.04s\n",
      "\n",
      "2024-06-12 03:00:14 (2.63 MB/s) - ‘../data/camels/camels_soil.txt’ saved [109125/109125]\n",
      "\n",
      "--2024-06-12 03:00:14--  https://gdex.ucar.edu/dataset/camels/file/camels_topo.txt\n",
      "Resolving gdex.ucar.edu (gdex.ucar.edu)... 128.117.181.6\n",
      "Connecting to gdex.ucar.edu (gdex.ucar.edu)|128.117.181.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 \n",
      "Length: 38677 (38K) [text/plain]\n",
      "Saving to: ‘../data/camels/camels_topo.txt’\n",
      "\n",
      "     0K .......... .......... .......... .......              100% 30.0M=0.001s\n",
      "\n",
      "2024-06-12 03:00:14 (30.0 MB/s) - ‘../data/camels/camels_topo.txt’ saved [38677/38677]\n",
      "\n",
      "--2024-06-12 03:00:14--  https://gdex.ucar.edu/dataset/camels/file/camels_vege.txt\n",
      "Resolving gdex.ucar.edu (gdex.ucar.edu)... 128.117.181.6\n",
      "Connecting to gdex.ucar.edu (gdex.ucar.edu)|128.117.181.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 \n",
      "Length: 107970 (105K) [text/plain]\n",
      "Saving to: ‘../data/camels/camels_vege.txt’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 47% 3.71M 0s\n",
      "    50K .......... .......... .......... .......... .......... 94% 3.72M 0s\n",
      "   100K .....                                                 100%  151M=0.03s\n",
      "\n",
      "2024-06-12 03:00:15 (3.91 MB/s) - ‘../data/camels/camels_vege.txt’ saved [107970/107970]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the directory where data will be stored\n",
    "DATA_DIR = \"../data/camels/\"\n",
    "\n",
    "# Remove the data directory if it already exists to ensure a fresh start\n",
    "if os.path.exists(DATA_DIR):\n",
    "    subprocess.run(['rm', '-Rf', DATA_DIR])\n",
    "\n",
    "# Create a new data directory\n",
    "os.makedirs(DATA_DIR)\n",
    "\n",
    "# List of filenames to be downloaded\n",
    "filenames = [\n",
    "    \"camels_clim.txt\", \"camels_geol.txt\", \"camels_hydro.txt\",\n",
    "    \"camels_name.txt\", \"camels_soil.txt\", \"camels_topo.txt\", \"camels_vege.txt\"\n",
    "]\n",
    "\n",
    "# Loop through each file and download it to the data directory\n",
    "for filename in filenames:\n",
    "    url = f\"https://gdex.ucar.edu/dataset/camels/file/{filename}\"\n",
    "    output_path = os.path.join(DATA_DIR, filename)\n",
    "    subprocess.run(['wget', '-O', output_path, url])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Share the Processing Code, Not Just the Processed Data\n",
    "\n",
    "Sharing the code used for data processing, rather than just the processed data, is crucial for ensuring reproducibility, especially in data science. While this approach might become challenging with very large datasets, it's essential for maintaining transparency and allowing others to understand and replicate your workflow. By sharing code, you provide insights into how raw data is transformed, cleaned, and made ready for analysis, which is invaluable for collaborative projects and scientific research.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of filenames to be loaded\n",
    "filenames = [\"camels_clim.txt\", \"camels_geol.txt\", \"camels_hydro.txt\",\n",
    "             \"camels_name.txt\", \"camels_soil.txt\", \"camels_topo.txt\", \"camels_vege.txt\"]\n",
    "\n",
    "# Dictionary to store DataFrames for each file\n",
    "dfs = {}\n",
    "\n",
    "# Loop through each file, read it into a DataFrame, and store it in the dictionary\n",
    "for filename in filenames:\n",
    "    with open(f\"../data/camels/{filename}\", \"r\") as f:\n",
    "        # Read the file using pandas, with ';' as the separator and 'gauge_id' as the index column\n",
    "        dfs[filename] = pd.read_csv(f, sep=\";\", index_col=\"gauge_id\")\n",
    "\n",
    "# Concatenate all DataFrames along the columns\n",
    "df = pd.concat([dfs[filename] for filename in filenames], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Text Data and NaN Values\n",
    "\n",
    "Once we consolidate all our data into a single DataFrame, we often encounter text data and NaN (Not a Number) values. Depending on our analysis goals, these may not be useful. For our current example, we require a dataset with complete information, meaning no missing values (NaNs), and our analysis will focus on continuous numerical data. Therefore, it's important to identify and appropriately handle text and NaN values to prepare our dataset for further analysis.\n",
    "\n",
    "Let's start by taking a preliminary look at our DataFrame to understand its structure and the nature of the data it contains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_mean</th>\n",
       "      <th>pet_mean</th>\n",
       "      <th>p_seasonality</th>\n",
       "      <th>frac_snow</th>\n",
       "      <th>aridity</th>\n",
       "      <th>high_prec_freq</th>\n",
       "      <th>high_prec_dur</th>\n",
       "      <th>high_prec_timing</th>\n",
       "      <th>low_prec_freq</th>\n",
       "      <th>low_prec_dur</th>\n",
       "      <th>...</th>\n",
       "      <th>area_geospa_fabric</th>\n",
       "      <th>frac_forest</th>\n",
       "      <th>lai_max</th>\n",
       "      <th>lai_diff</th>\n",
       "      <th>gvf_max</th>\n",
       "      <th>gvf_diff</th>\n",
       "      <th>dom_land_cover_frac</th>\n",
       "      <th>dom_land_cover</th>\n",
       "      <th>root_depth_50</th>\n",
       "      <th>root_depth_99</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gauge_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1013500</th>\n",
       "      <td>3.126679</td>\n",
       "      <td>1.971555</td>\n",
       "      <td>0.187940</td>\n",
       "      <td>0.313440</td>\n",
       "      <td>0.630559</td>\n",
       "      <td>12.95</td>\n",
       "      <td>1.348958</td>\n",
       "      <td>son</td>\n",
       "      <td>202.20</td>\n",
       "      <td>3.427119</td>\n",
       "      <td>...</td>\n",
       "      <td>2303.95</td>\n",
       "      <td>0.9063</td>\n",
       "      <td>4.167304</td>\n",
       "      <td>3.340732</td>\n",
       "      <td>0.804567</td>\n",
       "      <td>0.371648</td>\n",
       "      <td>0.883452</td>\n",
       "      <td>Mixed Forests</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022500</th>\n",
       "      <td>3.608126</td>\n",
       "      <td>2.119256</td>\n",
       "      <td>-0.114530</td>\n",
       "      <td>0.245259</td>\n",
       "      <td>0.587356</td>\n",
       "      <td>20.55</td>\n",
       "      <td>1.205279</td>\n",
       "      <td>son</td>\n",
       "      <td>233.65</td>\n",
       "      <td>3.662226</td>\n",
       "      <td>...</td>\n",
       "      <td>620.38</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>4.871392</td>\n",
       "      <td>3.746692</td>\n",
       "      <td>0.863936</td>\n",
       "      <td>0.337712</td>\n",
       "      <td>0.820493</td>\n",
       "      <td>Mixed Forests</td>\n",
       "      <td>0.237435</td>\n",
       "      <td>2.238444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030500</th>\n",
       "      <td>3.274405</td>\n",
       "      <td>2.043594</td>\n",
       "      <td>0.047358</td>\n",
       "      <td>0.277018</td>\n",
       "      <td>0.624111</td>\n",
       "      <td>17.15</td>\n",
       "      <td>1.207746</td>\n",
       "      <td>son</td>\n",
       "      <td>215.60</td>\n",
       "      <td>3.514262</td>\n",
       "      <td>...</td>\n",
       "      <td>3676.09</td>\n",
       "      <td>0.8782</td>\n",
       "      <td>4.685200</td>\n",
       "      <td>3.665543</td>\n",
       "      <td>0.858502</td>\n",
       "      <td>0.351393</td>\n",
       "      <td>0.975258</td>\n",
       "      <td>Mixed Forests</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031500</th>\n",
       "      <td>3.522957</td>\n",
       "      <td>2.071324</td>\n",
       "      <td>0.104091</td>\n",
       "      <td>0.291836</td>\n",
       "      <td>0.587950</td>\n",
       "      <td>18.90</td>\n",
       "      <td>1.148936</td>\n",
       "      <td>son</td>\n",
       "      <td>227.35</td>\n",
       "      <td>3.473644</td>\n",
       "      <td>...</td>\n",
       "      <td>766.53</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>4.903259</td>\n",
       "      <td>3.990843</td>\n",
       "      <td>0.870668</td>\n",
       "      <td>0.398619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Mixed Forests</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047000</th>\n",
       "      <td>3.323146</td>\n",
       "      <td>2.090024</td>\n",
       "      <td>0.147776</td>\n",
       "      <td>0.280118</td>\n",
       "      <td>0.628929</td>\n",
       "      <td>20.10</td>\n",
       "      <td>1.165217</td>\n",
       "      <td>son</td>\n",
       "      <td>235.90</td>\n",
       "      <td>3.691706</td>\n",
       "      <td>...</td>\n",
       "      <td>904.94</td>\n",
       "      <td>0.9906</td>\n",
       "      <td>5.086811</td>\n",
       "      <td>4.300978</td>\n",
       "      <td>0.891383</td>\n",
       "      <td>0.445473</td>\n",
       "      <td>0.850450</td>\n",
       "      <td>Mixed Forests</td>\n",
       "      <td>0.241027</td>\n",
       "      <td>2.340180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            p_mean  pet_mean  p_seasonality  frac_snow   aridity  \\\n",
       "gauge_id                                                           \n",
       "1013500   3.126679  1.971555       0.187940   0.313440  0.630559   \n",
       "1022500   3.608126  2.119256      -0.114530   0.245259  0.587356   \n",
       "1030500   3.274405  2.043594       0.047358   0.277018  0.624111   \n",
       "1031500   3.522957  2.071324       0.104091   0.291836  0.587950   \n",
       "1047000   3.323146  2.090024       0.147776   0.280118  0.628929   \n",
       "\n",
       "          high_prec_freq  high_prec_dur high_prec_timing  low_prec_freq  \\\n",
       "gauge_id                                                                  \n",
       "1013500            12.95       1.348958              son         202.20   \n",
       "1022500            20.55       1.205279              son         233.65   \n",
       "1030500            17.15       1.207746              son         215.60   \n",
       "1031500            18.90       1.148936              son         227.35   \n",
       "1047000            20.10       1.165217              son         235.90   \n",
       "\n",
       "          low_prec_dur  ... area_geospa_fabric frac_forest   lai_max  \\\n",
       "gauge_id                ...                                            \n",
       "1013500       3.427119  ...            2303.95      0.9063  4.167304   \n",
       "1022500       3.662226  ...             620.38      0.9232  4.871392   \n",
       "1030500       3.514262  ...            3676.09      0.8782  4.685200   \n",
       "1031500       3.473644  ...             766.53      0.9548  4.903259   \n",
       "1047000       3.691706  ...             904.94      0.9906  5.086811   \n",
       "\n",
       "          lai_diff   gvf_max  gvf_diff  dom_land_cover_frac  \\\n",
       "gauge_id                                                      \n",
       "1013500   3.340732  0.804567  0.371648             0.883452   \n",
       "1022500   3.746692  0.863936  0.337712             0.820493   \n",
       "1030500   3.665543  0.858502  0.351393             0.975258   \n",
       "1031500   3.990843  0.870668  0.398619             1.000000   \n",
       "1047000   4.300978  0.891383  0.445473             0.850450   \n",
       "\n",
       "             dom_land_cover  root_depth_50  root_depth_99  \n",
       "gauge_id                                                   \n",
       "1013500       Mixed Forests            NaN            NaN  \n",
       "1022500       Mixed Forests       0.237435       2.238444  \n",
       "1030500       Mixed Forests            NaN            NaN  \n",
       "1031500       Mixed Forests       0.250000       2.400000  \n",
       "1047000       Mixed Forests       0.241027       2.340180  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame to inspect its contents\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Data for Analysis\n",
    "\n",
    "In data analysis, the treatment of NaN (Not a Number) values depends on the context and objectives of your study. While NaNs can be acceptable or even meaningful in certain scenarios, they might not be suitable for others. In our hypothetical analysis, we require a dataset without any missing values. Therefore, we will remove columns containing NaN values to ensure our dataset is complete and ready for analysis.\n",
    "\n",
    "This step is crucial for maintaining the integrity and reliability of our analysis, as missing data can lead to biased or inaccurate results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove columns with any NaN values from the DataFrame\n",
    "df = df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Data Cleaning: Removing One Hot Encoded Data\n",
    "\n",
    "In many analytical scenarios, categorical data represented as strings or One Hot encoded data can be quite useful. However, for our specific analysis, we need a dataset consisting solely of numerical values. Therefore, we will identify and remove columns that contain string data, which often represent categorical variables.\n",
    "\n",
    "This step is crucial for aligning our dataset with the requirements of our analysis, ensuring that the data is in the correct format for the statistical or machine learning methods we plan to apply.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a list to hold the names of columns to be dropped\n",
    "drop_these_columns = []\n",
    "\n",
    "# Iterate over each column in the DataFrame\n",
    "for camels_data_column in df.columns.values:\n",
    "    # Check if the first value in the column is of string type\n",
    "    if type(df[camels_data_column].values[0]) == str:\n",
    "        # If it is a string, add the column name to the list\n",
    "        drop_these_columns.append(camels_data_column)\n",
    "\n",
    "# Drop the identified columns from the DataFrame\n",
    "df = df.drop(drop_these_columns, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Cleaned Data with a Unique Filename\n",
    "\n",
    "When sharing and managing data files, especially in a collaborative environment, it's good to avoid confusion caused by multiple versions of the same file. To prevent issues related to version control and ensure traceability, we'll save our cleaned dataset with a unique and descriptive filename. This filename will include the current date and time, along with the initials of the person who processed the data. Such a naming convention makes it easier to track changes over time and understand the lineage of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a timestamp string for the current date and time\n",
    "nowstring = datetime.today().strftime(\"%d-%m-%Y_%H%M\")\n",
    "\n",
    "# Initials of the data processor (change as needed)\n",
    "creator_initials = \"jf\"\n",
    "\n",
    "# Save the DataFrame to a CSV file with a unique name\n",
    "df.to_csv(f\"../data/camels/camels_attributes_cleaned_{nowstring}_{creator_initials}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
